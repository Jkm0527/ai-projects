Kaggle: spaceship titanic beginner competition
**Focus:**Tabular feature engineering and boosting models 

-Approach
  1. Exploratory Data Analysis (EDA) in Jupyter
  2. Feature engineering: categorical encoding, handling missing values, interaction terms
  3. Models: Random Forest classifier, XGBoost

-Things that could be improved
  1.Use different accuracy methods and other cv methods
  2.Ensemble the random forest classifier and xgboost model on top of eachother

-Results
  Random forest classifier accuracy: 0.8415
  xgboost accuracy:0.8438
